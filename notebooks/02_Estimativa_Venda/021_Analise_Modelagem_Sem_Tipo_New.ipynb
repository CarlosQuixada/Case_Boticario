{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa8226d-1b92-4d59-a255-3f0c663ab0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from scipy.stats import kruskal\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0b94ca-efe6-47e6-b40e-ef418671e4f6",
   "metadata": {},
   "source": [
    "- Vou criar o modelo utilizando apenas os dados que não tiveram ruptura pois os valores das vendas são mais próximos dos reais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0af060-71b0-44ca-a62a-158bdc30dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/processed/dados_features_Sem_Tipo.csv')\n",
    "df['dt_estoque'] = pd.to_datetime(df['dt_estoque'])\n",
    "df = df[df['is_ruptura']==0]\n",
    "df.drop(columns=['tipo_demanda', 'qtd_venda_interp', 'is_ruptura', 'qt_estoque'], inplace=True)\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d51e28f-6ddd-44e4-9746-3dc4b9f87e42",
   "metadata": {},
   "source": [
    "# Split Treino / Teste "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4380a8e-8cb3-4628-8e22-8d2758855e0d",
   "metadata": {},
   "source": [
    "- Como Transformei a previsão de venda em um problema tabular vou realizar o split treino/teste de forma aleatória com 80% no treino e 20% no teste de cada combinação loja + produto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b4f3f3-0786-4501-84ee-a20669a77186",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_grupo_robusto(grupo):\n",
    "    n = len(grupo)\n",
    "    \n",
    "    if n == 1:\n",
    "        # Apenas 1 registro → tudo no treino\n",
    "        return pd.Series(['treino'], index=grupo.index)\n",
    "    \n",
    "    elif n == 2:\n",
    "        # 50/50 para dois registros\n",
    "        return pd.Series(['treino', 'teste'], index=grupo.sample(frac=1, random_state=42).index)\n",
    "    \n",
    "    else:\n",
    "        # Split aleatório 80/20 para grupos maiores\n",
    "        treino_idx, teste_idx = train_test_split(grupo.index, test_size=0.2, random_state=42)\n",
    "        split = pd.Series('treino', index=grupo.index)\n",
    "        split.loc[teste_idx] = 'teste'\n",
    "        return split\n",
    "\n",
    "df['grupo_split'] = df.groupby(['key_loja', 'cod_produto']).apply(split_grupo_robusto).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba29f0f-3113-4d4e-b377-b4434f87124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['grupo_split'] == 'treino'].copy()\n",
    "df_test = df[df['grupo_split'] == 'teste'].copy()\n",
    "\n",
    "df_train.drop(columns=['grupo_split'], inplace=True)\n",
    "df_test.drop(columns=['grupo_split'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec0ded5-b435-4131-98b5-1ec1230b7db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Treino:\", df_train.shape)\n",
    "print(\"Teste :\", df_test.shape)\n",
    "\n",
    "# Checar se todas as combinações estão em ambos\n",
    "combos_treino = set(df_train[['key_loja', 'cod_produto']].apply(tuple, axis=1))\n",
    "combos_teste  = set(df_test[['key_loja', 'cod_produto']].apply(tuple, axis=1))\n",
    "print(\"Apenas no treino:\", combos_treino - combos_teste)\n",
    "print(\"Apenas no teste :\", combos_teste - combos_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ebca99-4de7-4b68-bc2e-bd1da30a9cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feat_cat = ['des_estado_franquia', 'categoria_produto', 'sub_categoria_produto', 'linha_produto', 'day_of_the_week', 'key_loja', 'cod_produto']\n",
    "\n",
    "list_feat_num = ['vlr_venda_tabelado_mean', 'qtd_vendas_media_1d', 'qtd_vendas_mediana_1d', 'qtd_vendas_max_1d', 'qtd_vendas_min_1d', 'qtd_vendas_media_7d', 'qtd_vendas_mediana_7d', \n",
    "                 'qtd_vendas_max_7d', 'qtd_vendas_min_7d', 'qtd_vendas_media_30d', 'qtd_vendas_mediana_30d', 'qtd_vendas_max_30d', 'qtd_vendas_min_30d', 'qtd_vendas_media_60d', \n",
    "                 'qtd_vendas_mediana_60d', 'qtd_vendas_max_60d', 'qtd_vendas_min_60d', 'media_1d_7d_ratio_qtd_vendas', 'media_1d_30d_ratio_qtd_vendas', 'media_1d_60d_ratio_qtd_vendas', \n",
    "                 'media_7d_30d_ratio_qtd_vendas', 'media_7d_60d_ratio_qtd_vendas', 'media_30d_60d_ratio_qtd_vendas', 'mediana_1d_7d_ratio_qtd_vendas', 'mediana_1d_30d_ratio_qtd_vendas', \n",
    "                 'mediana_1d_60d_ratio_qtd_vendas', 'mediana_7d_30d_ratio_qtd_vendas', 'mediana_7d_60d_ratio_qtd_vendas', 'mediana_30d_60d_ratio_qtd_vendas', 'max_1d_7d_ratio_qtd_vendas', \n",
    "                 'max_1d_30d_ratio_qtd_vendas', 'max_1d_60d_ratio_qtd_vendas', 'max_7d_30d_ratio_qtd_vendas', 'max_7d_60d_ratio_qtd_vendas', 'max_30d_60d_ratio_qtd_vendas', \n",
    "                 'min_1d_7d_ratio_qtd_vendas', 'min_1d_30d_ratio_qtd_vendas', 'min_1d_60d_ratio_qtd_vendas', 'min_7d_30d_ratio_qtd_vendas', 'min_7d_60d_ratio_qtd_vendas', \n",
    "                 'min_30d_60d_ratio_qtd_vendas', 'vlr_venda_tabelado_mean_media_1d', 'vlr_venda_tabelado_mean_mediana_1d', 'vlr_venda_tabelado_mean_max_1d', 'vlr_venda_tabelado_mean_min_1d', \n",
    "                 'vlr_venda_tabelado_mean_media_7d', 'vlr_venda_tabelado_mean_mediana_7d', 'vlr_venda_tabelado_mean_max_7d', 'vlr_venda_tabelado_mean_min_7d', 'vlr_venda_tabelado_mean_media_30d', \n",
    "                 'vlr_venda_tabelado_mean_mediana_30d', 'vlr_venda_tabelado_mean_max_30d', 'vlr_venda_tabelado_mean_min_30d', 'vlr_venda_tabelado_mean_media_60d', \n",
    "                 'vlr_venda_tabelado_mean_mediana_60d', 'vlr_venda_tabelado_mean_max_60d', 'vlr_venda_tabelado_mean_min_60d', 'media_1d_7d_ratio_vlr_venda_tabelado_mean', \n",
    "                 'media_1d_30d_ratio_vlr_venda_tabelado_mean', 'media_1d_60d_ratio_vlr_venda_tabelado_mean', 'media_7d_30d_ratio_vlr_venda_tabelado_mean', \n",
    "                 'media_7d_60d_ratio_vlr_venda_tabelado_mean', 'media_30d_60d_ratio_vlr_venda_tabelado_mean', 'mediana_1d_7d_ratio_vlr_venda_tabelado_mean', \n",
    "                 'mediana_1d_30d_ratio_vlr_venda_tabelado_mean', 'mediana_1d_60d_ratio_vlr_venda_tabelado_mean', 'mediana_7d_30d_ratio_vlr_venda_tabelado_mean', \n",
    "                 'mediana_7d_60d_ratio_vlr_venda_tabelado_mean', 'mediana_30d_60d_ratio_vlr_venda_tabelado_mean', 'max_1d_7d_ratio_vlr_venda_tabelado_mean', \n",
    "                 'max_1d_30d_ratio_vlr_venda_tabelado_mean', 'max_1d_60d_ratio_vlr_venda_tabelado_mean', 'max_7d_30d_ratio_vlr_venda_tabelado_mean', 'max_7d_60d_ratio_vlr_venda_tabelado_mean', \n",
    "                 'max_30d_60d_ratio_vlr_venda_tabelado_mean', 'min_1d_7d_ratio_vlr_venda_tabelado_mean', 'min_1d_30d_ratio_vlr_venda_tabelado_mean', 'min_1d_60d_ratio_vlr_venda_tabelado_mean', \n",
    "                 'min_7d_30d_ratio_vlr_venda_tabelado_mean', 'min_7d_60d_ratio_vlr_venda_tabelado_mean', 'min_30d_60d_ratio_vlr_venda_tabelado_mean', 'qt_estoque_media_1d', \n",
    "                 'qt_estoque_mediana_1d', 'qt_estoque_max_1d', 'qt_estoque_min_1d', 'qt_estoque_media_7d', 'qt_estoque_mediana_7d', 'qt_estoque_max_7d', 'qt_estoque_min_7d', \n",
    "                 'qt_estoque_media_30d', 'qt_estoque_mediana_30d', 'qt_estoque_max_30d', 'qt_estoque_min_30d', 'qt_estoque_media_60d', 'qt_estoque_mediana_60d', 'qt_estoque_max_60d', \n",
    "                 'qt_estoque_min_60d', 'media_1d_7d_ratio_qt_estoque', 'media_1d_30d_ratio_qt_estoque', 'media_1d_60d_ratio_qt_estoque', 'media_7d_30d_ratio_qt_estoque', \n",
    "                 'media_7d_60d_ratio_qt_estoque', 'media_30d_60d_ratio_qt_estoque', 'mediana_1d_7d_ratio_qt_estoque', 'mediana_1d_30d_ratio_qt_estoque', 'mediana_1d_60d_ratio_qt_estoque', \n",
    "                 'mediana_7d_30d_ratio_qt_estoque', 'mediana_7d_60d_ratio_qt_estoque', 'mediana_30d_60d_ratio_qt_estoque', 'max_1d_7d_ratio_qt_estoque', 'max_1d_30d_ratio_qt_estoque', \n",
    "                 'max_1d_60d_ratio_qt_estoque', 'max_7d_30d_ratio_qt_estoque', 'max_7d_60d_ratio_qt_estoque', 'max_30d_60d_ratio_qt_estoque', 'min_1d_7d_ratio_qt_estoque', \n",
    "                 'min_1d_30d_ratio_qt_estoque', 'min_1d_60d_ratio_qt_estoque', 'min_7d_30d_ratio_qt_estoque', 'min_7d_60d_ratio_qt_estoque', 'min_30d_60d_ratio_qt_estoque']\n",
    "\n",
    "list_no_feat = ['dt_estoque', 'qtd_vendas']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a081afb-0ca5-4138-8ea2-4258ff149f03",
   "metadata": {},
   "source": [
    "# Validando Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e840177-67f6-4c05-aed0-2abd72158e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_features_null(df, list_feat):\n",
    "    grouped = df.groupby(['key_loja', 'cod_produto'])\n",
    "\n",
    "    # Avalia só nas features que você escolheu\n",
    "    percent_nulos_por_grupo = grouped[list_feat].apply(lambda g: g.isnull().mean())\n",
    "    \n",
    "    # Média por feature\n",
    "    percent_nulos_por_feature = percent_nulos_por_grupo.mean().sort_values(ascending=False) * 100\n",
    "    \n",
    "    # # Plotando\n",
    "    # plt.figure(figsize=(12, max(6, len(percent_nulos_por_feature) * 0.5)))\n",
    "    # ax = percent_nulos_por_feature.plot(kind='barh')\n",
    "    \n",
    "    # # Adiciona os valores ao lado das barras\n",
    "    # for i, (valor, nome_coluna) in enumerate(zip(percent_nulos_por_feature, percent_nulos_por_feature.index)):\n",
    "    #     ax.text(valor + 0.5, i, f\"{valor:.1f}%\", va='center', fontsize=10)\n",
    "    \n",
    "    # # Formatação do gráfico\n",
    "    # plt.xlabel(\"% de valores nulos (média por loja + produto)\")\n",
    "    # plt.title(\"Porcentagem de Nulos por Feature Selecionada\")\n",
    "    # plt.gca().invert_yaxis()\n",
    "    # plt.grid(True, axis='x')\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    return percent_nulos_por_feature.to_frame().reset_index().rename(columns={0:'perct_nulo'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd58d51-14b9-4e21-8861-bd8cda42d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[list_feat_cat].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe24ae7-6a97-40e0-bf9d-c5f81aba1ec0",
   "metadata": {},
   "source": [
    "- Nenhuma Feature Categórica estava como nula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07dd866-e909-48fc-9859-a152f68a7047",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_percent_nulos_por_feature = validate_features_null(df, list_feat_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdc9c9e-9c00-4a5c-857c-9974ecda4b0d",
   "metadata": {},
   "source": [
    "- Irei Remover todas as features que tiverem >= 50% nulas. Pois se realizar imputação dos valores nulos irei adicionar viés desnecessário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16526462-67d1-4277-9996-22240b00a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feat_remove_null_num = df_percent_nulos_por_feature[df_percent_nulos_por_feature['perct_nulo']>=50]['index'].values\n",
    "list_feat_restantes_null = df_percent_nulos_por_feature[df_percent_nulos_por_feature['perct_nulo']<50]['index'].values\n",
    "list_feat_remove_null_num[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29063c51-47b6-4ec8-8f7a-7ae1370e3138",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feat_num = list(set(list_feat_num)-set(list_feat_remove_null_num))\n",
    "list_feat_num[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672adfaa-5ce7-42e3-b8f3-d06f3ac4469b",
   "metadata": {},
   "source": [
    "- Para as Features que numéricas que restaram irei testar se a melhor solução será imputar valores ou imputar valores e marcar com flag de nulo:\n",
    "    - Features de qtd_estoque e qtd_venda irei imputar 0\n",
    "    - Features de preço irei imputar a mediana dessa coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2032e004-fad0-4d08-ab86-14af73e848e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['qtd_vendas']\n",
    "y_test = df_test['qtd_vendas']\n",
    "\n",
    "# =====================\n",
    "# Versão A e B: Imputar com regras\n",
    "# =====================\n",
    "X_train_a = df_train[list_feat_restantes_null]\n",
    "X_test_a = df_test[list_feat_restantes_null]\n",
    "X_train_b = X_train_a.copy()\n",
    "X_test_b = X_test_a.copy()\n",
    "\n",
    "\n",
    "# X_train_a.shape, X_test_a.shape , X_train_b.shape, X_test_b.shape, y_train.shape, y_test.shape\n",
    "for col in list_feat_restantes_null:\n",
    "    if 'qtd_estoque' in col or 'qtd_venda' in col:\n",
    "        imput_value = 0\n",
    "    elif 'vlr_venda_tabelado_mean' in col:\n",
    "        imput_value = df_train[col].median()\n",
    "    else:\n",
    "        imput_value = df_train[col].median()\n",
    "\n",
    "    # Imputação simples para B e C\n",
    "    X_train_a[col] = X_train_a[col].fillna(imput_value)\n",
    "    X_test_a[col] = X_test_a[col].fillna(imput_value)\n",
    "    X_train_b[col] = X_train_b[col].fillna(imput_value)\n",
    "    X_test_b[col] = X_test_b[col].fillna(imput_value)\n",
    "\n",
    "    # Adicionar flag de nulo em B \n",
    "    X_train_b[f'is_null_{col}'] = df_train[col].isnull().astype(int)\n",
    "    X_test_b[f'is_null_{col}'] = df_test[col].isnull().astype(int)\n",
    "\n",
    "# =====================\n",
    "# Modelos A e B\n",
    "# =====================\n",
    "model_a = LGBMRegressor(random_state=42, verbose=0)\n",
    "model_a.fit(X_train_a, y_train)\n",
    "mae_a = mean_absolute_error(y_test, model_a.predict(X_test_a))\n",
    "\n",
    "model_b = LGBMRegressor(random_state=42, verbose=0)\n",
    "model_b.fit(X_train_b, y_train)\n",
    "mae_b = mean_absolute_error(y_test, model_b.predict(X_test_b))\n",
    "\n",
    "# =====================\n",
    "# Resultados\n",
    "# =====================\n",
    "print(\"MAE - A (imputação):\", round(mae_a, 4))\n",
    "print(\"MAE - B (Imputação + flag):\", round(mae_b, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d79117-e0e4-4dc6-906f-f565d3c962d8",
   "metadata": {},
   "source": [
    "- Então para esse modelo irei utilizar a imputação dos nulos apenas seguindo a regra acima "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e787fe4-2b95-4a7d-9a26-b05afbf8147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in list_feat_num:\n",
    "    if 'qtd_estoque' in col or 'qtd_venda' in col:\n",
    "        imput_value = 0\n",
    "    elif 'vlr_venda_tabelado_mean' in col:\n",
    "        imput_value = df_train[col].median()\n",
    "    else:\n",
    "        imput_value = df_train[col].median()\n",
    "\n",
    "    # Imputação simples para B e C\n",
    "    df_train[col] = df_train[col].fillna(imput_value)\n",
    "    df_test[col] = df_test[col].fillna(imput_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4b2ac2-c7fd-47d5-abef-a15a8cecc812",
   "metadata": {},
   "source": [
    "- Não vou fazer tratamento de valores nulos, pois irei utilizar o modelo Catboost que aceita valores NaN, qualquer tratamento que eu fizer pode gerar viés"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c262ad-5bad-4b39-a0d3-fd0ea1a4cd05",
   "metadata": {},
   "source": [
    "# Avaliação Importancia das Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a603c9-b1d1-437b-be40-0c378ee40e27",
   "metadata": {},
   "source": [
    "## Categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f46b46c-deb9-4b3c-9ec1-d9bd836e8f90",
   "metadata": {},
   "source": [
    "- As Features Categoricas irão receber um tratamento de one hot encoder para poderem serem utilizadas pelo modelo LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbeba25-c6f8-4c61-8fcd-6ad0e9f7b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def transform_one_hot_encode(train, test, cols_categoricas):\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "    # Codificar as colunas categóricas\n",
    "    train_codificadas = encoder.fit_transform(train[cols_categoricas])\n",
    "    test_codificadas = encoder.fit_transform(test[cols_categoricas])\n",
    "    \n",
    "    # Criar nomes das novas colunas\n",
    "    nomes_colunas = encoder.get_feature_names_out(cols_categoricas)\n",
    "    \n",
    "    # DataFrame das variáveis codificadas\n",
    "    df_train_oh = pd.DataFrame(train_codificadas, columns=nomes_colunas, index=train.index)\n",
    "    df_test_oh = pd.DataFrame(test_codificadas, columns=nomes_colunas, index=test.index)\n",
    "\n",
    "    # Concatenar com as colunas não categóricas\n",
    "    df_train_restante = train.drop(columns=cols_categoricas)\n",
    "    df_train_encoded = pd.concat([df_train_restante, df_train_oh], axis=1)\n",
    "\n",
    "    df_test_restante = test.drop(columns=cols_categoricas)\n",
    "    df_test_encoded = pd.concat([df_test_restante, df_test_oh], axis=1)\n",
    "\n",
    "    return df_train_encoded, df_test_encoded, encoder, nomes_colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71d074e-f87b-4399-9f6e-00028f97c9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded, df_test_encoded, encoder, list_feat_cat_encoder = transform_one_hot_encode(df_train, df_test, list_feat_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e016254c-8cfb-4cc9-8ec5-479207d68c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliar_categorica_kruskal(df, col_categ, col_y):\n",
    "    grupos = df[[col_categ, col_y]].dropna().groupby(col_categ)[col_y].apply(list)\n",
    "\n",
    "    if len(grupos) < 2:\n",
    "        return None, None  # Não tem comparação válida\n",
    "\n",
    "    try:\n",
    "        stat, pvalue = kruskal(*grupos)\n",
    "        return stat, pvalue\n",
    "    except Exception as e:\n",
    "        print(f\"Erro em {col_categ}: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5810fc43-c4da-4ed8-8a35-f874e9c1b765",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_cat = []\n",
    "\n",
    "for col in list_feat_cat_encoder:  # ex: ['tipo_loja', 'categoria_produto']\n",
    "    stat, p = avaliar_categorica_kruskal(df_train_encoded, col, 'qtd_vendas')\n",
    "    if stat is not None:\n",
    "        decisao = 'RELEVANTE' if p < 0.05 else 'DESCARTAR'\n",
    "        resultados_cat.append((col, stat, p, decisao))\n",
    "\n",
    "# Salvar em DataFrame\n",
    "df_resultados_cat = pd.DataFrame(resultados_cat, columns=['feature', 'stat_H', 'p_value', 'decisao'])\n",
    "df_resultados_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd674b-9542-482e-9571-9e50a9ba6759",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_rel_cat = list(df_resultados_cat[df_resultados_cat['decisao']=='RELEVANTE']['feature'].values)\n",
    "list_feat_cat_encoder = list(set(list_feat_cat_encoder).intersection(list_rel_cat))\n",
    "len(list_feat_cat_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5846aff6-bdb2-425e-bcf7-9294f00ae0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "def create_grid_barplots(df, cols_categoricas, col_y, n_cols=5):\n",
    "    n = len(cols_categoricas)\n",
    "    n_rows = math.ceil(n / n_cols)\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 5 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, col in enumerate(cols_categoricas):\n",
    "        ax = axes[i]\n",
    "        # Agrupa e ordena decrescentemente\n",
    "        df_aux = df.groupby(col)[col_y].sum().reset_index().sort_values(by=col_y, ascending=False)\n",
    "        \n",
    "        sns.barplot(x=col, y=col_y, data=df_aux, ax=ax, order=df_aux[col])\n",
    "        # ax.set_title(f\"{col} x {col_y}\")\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel(col_y)\n",
    "\n",
    "        # Adiciona os valores sobre as barras\n",
    "        for bar, value in zip(ax.patches, df_aux[col_y]):\n",
    "            ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), round(value, 2),\n",
    "                    ha='center', va='bottom', color='black', fontsize=9)\n",
    "\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Remove gráficos extras (caso n < n_rows * n_cols)\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecac0a70-a1ac-4bb1-a441-3e8506603105",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feat_cat_encoder[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24363a98-c946-4e84-a2a5-6ff29edc01f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_grid_barplots(df_train_encoded, list_feat_cat_encoder[0:10], 'qtd_vendas', n_cols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfa7c56-edff-42f2-848a-48c40209d744",
   "metadata": {},
   "source": [
    "## Numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416604cb-2083-4370-8391-1276c026ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificar_percentil(df, list_features_num):\n",
    "    df_copy = df.copy()\n",
    "    colunas_sucesso = []\n",
    "    colunas_falhas = []\n",
    "    \n",
    "    percentis = [0.05, 0.25, 0.5, 0.75, 0.95]\n",
    "    rotulos = ['P05', 'P25', 'P50', 'P75', 'P95']\n",
    "    \n",
    "    for col in list_features_num:\n",
    "        try:\n",
    "            limites = df[col].quantile(percentis).values\n",
    "            bins = [-np.inf] + list(limites) + [np.inf]\n",
    "            labels = rotulos + ['>P95']\n",
    "            df_copy[f'{col}_percentil'] = pd.cut(\n",
    "                df[col], bins=bins, labels=labels, include_lowest=True, duplicates='drop'\n",
    "            )\n",
    "            colunas_sucesso.append(f'{col}_percentil')\n",
    "        except ValueError as e:\n",
    "            colunas_falhas = [].append(col)\n",
    "            print(f\"⚠️ Erro ao classificar '{col}': {e}\")\n",
    "\n",
    "    return df_copy, colunas_sucesso, colunas_falhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812c7de7-d0e0-4746-a0bf-c52ae07a0458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupar_extremos_percentil(df, cols_percentil):\n",
    "    df_copy = df.copy()\n",
    "    for col in cols_percentil:\n",
    "        if '>P95' in df_copy[col].unique():\n",
    "            df_copy[col] = df_copy[col].replace('>P95', 'P95')\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167f5253-471c-4c94-82a9-8e8b1ac1b49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identificar_features_nao_ordenadas(df, cols_percentil, col_y='qtd_vendas'):\n",
    "    features_nao_ordenadas = []\n",
    "\n",
    "    for col in cols_percentil:\n",
    "        # Calcula a média de vendas por grupo de percentil\n",
    "        medias = df.groupby(col)[col_y].mean().dropna()\n",
    "        valores = medias.values\n",
    "\n",
    "        # Verifica se está ordenado (crescente ou decrescente)\n",
    "        if not (np.all(np.diff(valores) >= 0) or np.all(np.diff(valores) <= 0)):\n",
    "            features_nao_ordenadas.append(col)\n",
    "\n",
    "    return features_nao_ordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529af19b-daf6-4221-8e49-85ae7aedfd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_com_percentis, colunas_sucesso, colunas_falhas = classificar_percentil(df_train_encoded, list_feat_num)\n",
    "df_percentil_agrupado = agrupar_extremos_percentil(df_com_percentis, colunas_sucesso)\n",
    "df_percentil_agrupado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b74328-b0d1-46d4-a1f0-6e9072cd0f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_grid_barplots(df_percentil_agrupado, colunas_sucesso, 'qtd_vendas', n_cols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6dc567-dced-4109-97f8-65a8d6ed4991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliar_feature_percentil_kruskal(df, col_percentil, col_y):\n",
    "    # Agrupa por categoria da feature (ex: P05, P25, ...)\n",
    "    grupos = df[[col_percentil, col_y]].dropna().groupby(col_percentil)[col_y].apply(list)\n",
    "    \n",
    "    if len(grupos) < 2:\n",
    "        return None, None  # Não dá para testar com < 2 grupos\n",
    "\n",
    "    # Aplica o teste de Kruskal-Wallis\n",
    "    stat, pvalue = kruskal(*grupos)\n",
    "    return stat, pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd90f650-2008-4ca5-91e2-b8ac66bc18bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "\n",
    "for col in colunas_sucesso:  # ex: ['preco_percentil', 'estoque_percentil']\n",
    "    stat, p = avaliar_feature_percentil_kruskal(df_percentil_agrupado, col, 'qtd_vendas')\n",
    "    \n",
    "    if stat is not None:\n",
    "        resultados.append((str(col).replace('_percentil', ''), stat, p, 'RELEVANTE' if p < 0.05 else 'DESCARTAR'))\n",
    "\n",
    "# Ordenar por p-valor\n",
    "resultados = sorted(resultados, key=lambda x: x[2])\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados, columns=['feature', 'stat_H', 'p_value', 'decisao'])\n",
    "\n",
    "# Exibir\n",
    "df_resultados[df_resultados['decisao'] == 'DESCARTAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce967b-d5f5-49df-8892-d155c1edb92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feat_num = list(df_resultados[df_resultados['decisao'] == 'RELEVANTE']['feature'].values)\n",
    "len(list_feat_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485f9c31-c853-4ba6-aa24-23b7147e3985",
   "metadata": {},
   "source": [
    "## Feature Selection por Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265b0cba-2a6d-42ed-b1f6-6d4e067b5100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def selecionar_features_por_importancia(X, y, top_k=None, threshold=None):\n",
    "    model = LGBMRegressor(\n",
    "        verbose=0,\n",
    "        random_state=42,\n",
    "    )\n",
    "    model.fit(X, y)\n",
    "\n",
    "    importancias = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values(by='importance', ascending=False)\n",
    "\n",
    "    # Selecionar por critério\n",
    "    if top_k is not None:\n",
    "        selecionadas = importancias.head(top_k)['feature'].tolist()\n",
    "    elif threshold is not None:\n",
    "        selecionadas = importancias[importancias['importance'] >= threshold]['feature'].tolist()\n",
    "    else:\n",
    "        selecionadas = importancias[importancias['importance'] > 0]['feature'].tolist()\n",
    "\n",
    "    return selecionadas, importancias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd496d49-2f78-4c49-b140-7de61e0d8c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feat = list_feat_cat_encoder.copy()\n",
    "list_feat.extend(list_feat_num)\n",
    "list_feat = list(set(list_feat))\n",
    "len(list_feat), len(list_feat_cat_encoder), len(list_feat_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c4c55d-27b4-4586-b333-3100065148c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar X e y\n",
    "X = df_train_encoded[list_feat]\n",
    "y = df_train_encoded['qtd_vendas']\n",
    "\n",
    "# # Executar seleção\n",
    "features_boas, ranking = selecionar_features_por_importancia(X, y, top_k=20)\n",
    "# features_boas.append('key_loja')\n",
    "# features_boas.append('cod_produto')\n",
    "\n",
    "list_feat_final = list(set(features_boas))\n",
    "print(\"Features selecionadas:\", list_feat_final)\n",
    "print(\"\\nRanking completo:\")\n",
    "print(ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c335508-2fcd-433e-aa23-7312a6936b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feat_cat = list(set(list_feat_cat).intersection(list_feat_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e3b687-6227-4a05-9bb3-7a55dd66da4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_feat_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02553dde-1613-402c-9c51-4cf94aabcd76",
   "metadata": {},
   "source": [
    "# Treinamento Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44237972-54ec-4592-a269-6ed068901b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_encoded[list_feat_final]\n",
    "y_train = df_train_encoded['qtd_vendas']\n",
    "\n",
    "X_test = df_test_encoded[list_feat_final]\n",
    "y_test = df_test_encoded['qtd_vendas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3c4aa4-9831-49b2-b1ca-612b534dd937",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_encoded.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13f9a2c-ed16-46ff-84ab-6c37c2534a72",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68377068-5c9a-421a-b3bf-3464bb4b04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) + 1e-8\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bc4795-2316-486c-8267-dafa09c81d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No treino: calcula a mediana por grupo\n",
    "mediana_por_grupo = df_train.groupby(['key_loja', 'cod_produto'])['qtd_vendas'].median().reset_index()\n",
    "mediana_por_grupo.rename(columns={'qtd_vendas':'qtd_vendas_pred'}, inplace=True)\n",
    "\n",
    "X_train_pred = df_train.merge(mediana_por_grupo, on=['key_loja', 'cod_produto'], how='left')\n",
    "X_train_pred.fillna(value={'qtd_vendas_pred':0})\n",
    "\n",
    "X_test_pred = df_test.merge(mediana_por_grupo, on=['key_loja', 'cod_produto'], how='left')\n",
    "X_test_pred.fillna(value={'qtd_vendas_pred':0})\n",
    "\n",
    "mae_baseline_test = mean_absolute_error(y_test, X_test_pred['qtd_vendas_pred'])\n",
    "smape_baseline_test = smape(y_test, X_test_pred['qtd_vendas_pred'])\n",
    "print(f\"MAE do baseline Teste: {mae_baseline_test:.2f} | SMAPE baseline Teste: {smape_baseline_test:.2f}\")\n",
    "\n",
    "mae_baseline_train = mean_absolute_error(y_train, X_train_pred['qtd_vendas_pred'])\n",
    "smape_baseline_train = smape(y_train, X_train_pred['qtd_vendas_pred'])\n",
    "print(f\"MAE do baseline Train: {mae_baseline_train:.2f}  | SMAPE baseline Train: {smape_baseline_train:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca0c317-477f-4534-8279-bc87c7334ef2",
   "metadata": {},
   "source": [
    "## Tunnig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6386f365-b1c6-4c67-b7b1-60c61b75f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "def objective(trial, X, y):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 900),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.5),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 1.0),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "\n",
    "    cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    maes = []\n",
    "\n",
    "    for train_idx, valid_idx in cv.split(X):\n",
    "        X_train_fold, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train_fold, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        model = LGBMRegressor(**params, verbose=-1)\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        preds = model.predict(X_valid)\n",
    "        mae = mean_absolute_error(y_valid, preds)\n",
    "        maes.append(mae)\n",
    "\n",
    "    return np.median(maes)\n",
    "\n",
    "def rodar_otimizacao_bayesiana(X, y, n_trials=50):\n",
    "    study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "    study.optimize(lambda trial: objective(trial, X, y), n_trials=n_trials)\n",
    "\n",
    "    return study.best_trial, study.best_params, study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556e7eae-a34c-4617-b76b-dbc5f80c33bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rode a otimização bayesiana\n",
    "best_trial, best_params, study = rodar_otimizacao_bayesiana(X_train, y_train, n_trials=50)\n",
    "\n",
    "print(\"Melhores hiperparâmetros encontrados:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ae82ad-0609-4a8b-8ba0-b1a8fe606ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE do baseline Teste: 2.95 | SMAPE baseline Teste: 103.20\n",
    "MAE do baseline Train: 2.88  | SMAPE baseline Train: 102.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b2611c-eeaf-49d1-80c8-d2b51a5ddcdb",
   "metadata": {},
   "source": [
    "- {'iterations': 685, 'learning_rate': 0.06422534481531783, 'depth': 8, 'l2_leaf_reg': 4.978107035094452, 'bagging_temperature': 0.7445378048598745, 'random_strength': 1.016900496982359}\n",
    "    - MAE do baseline Teste: 1.89 | SMAPE baseline Teste: 100.81\n",
    "    - MAE do baseline Train: 1.43  | SMAPE baseline Train: 98.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4953e8-5dd4-4bb6-a041-64b577ffa56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(**best_params, verbose=-1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "mae_baseline_test = mean_absolute_error(y_test, y_test_pred)\n",
    "smape_baseline_test = smape(y_test, y_test_pred)\n",
    "print(f\"MAE do baseline Teste: {mae_baseline_test:.2f} | SMAPE baseline Teste: {smape_baseline_test:.2f}\")\n",
    "\n",
    "mae_baseline_train = mean_absolute_error(y_train, y_train_pred)\n",
    "smape_baseline_train = smape(y_train, y_train_pred)\n",
    "print(f\"MAE do baseline Train: {mae_baseline_train:.2f}  | SMAPE baseline Train: {smape_baseline_train:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d95a341-ac83-433f-9445-1c6b381d9a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d77b24-96e8-4da1-ba9a-13412a8a93a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7fb5ad-4960-42b3-adad-87a287628e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
